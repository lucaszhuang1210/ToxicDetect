{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (2.0.0)\r\n",
      "Requirement already satisfied: nltk in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (1.3.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\r\n",
      "Requirement already satisfied: regex in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\r\n",
      "Requirement already satisfied: click in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\r\n",
      "Requirement already satisfied: joblib in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.20.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\r\n",
      "Requirement already satisfied: torchvision in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (0.10.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (1.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (0.0.12)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (4.9.2)\r\n",
      "Requirement already satisfied: sentencepiece in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (0.1.96)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\r\n",
      "Requirement already satisfied: requests in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.25.1)\r\n",
      "Requirement already satisfied: packaging in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.9)\r\n",
      "Requirement already satisfied: sacremoses in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\r\n",
      "Requirement already satisfied: filelock in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.4)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2024.8.30)\r\n",
      "Requirement already satisfied: six in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\r\n",
      "Requirement already satisfied: pillow>=5.3.0 in /Users/lucaszhuang1210gmail.com/opt/anaconda3/lib/python3.8/site-packages (from torchvision->sentence-transformers) (8.2.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lucaszhuang1210gmail.com/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages (run this cell once)\n",
    "%pip install sentence-transformers nltk scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')  # Download stopwords for potential text cleaning\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# This cell installs and imports all required libraries, laying the foundation for our text processing and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file found at: ./data/train.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      id                                       comment_text  \\\n0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n...                  ...                                                ...   \n159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n0           0             0        0       0       0              0  \n1           0             0        0       0       0              0  \n2           0             0        0       0       0              0  \n3           0             0        0       0       0              0  \n4           0             0        0       0       0              0  \n...       ...           ...      ...     ...     ...            ...  \n159566      0             0        0       0       0              0  \n159567      0             0        0       0       0              0  \n159568      0             0        0       0       0              0  \n159569      0             0        0       0       0              0  \n159570      0             0        0       0       0              0  \n\n[159571 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159566</th>\n      <td>ffe987279560d7ff</td>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>ffea4adeee384e90</td>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>ffee36eab5c267c9</td>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>fff125370e4aaaf3</td>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>fff46fc426af1f9a</td>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159571 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Kaggle Toxic Comment Challenge training data (ensure 'train.csv' is in your working directory)\n",
    "data_file = os.path.join('.', 'data', 'train.csv')\n",
    "# Check if the data file exists\n",
    "if not os.path.exists(data_file):\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_file}. Please ensure the file exists in the './data/' directory.\")\n",
    "else:\n",
    "    print(f\"Data file found at: {data_file}\")\n",
    "\n",
    "# Load the Kaggle Toxic Comment Challenge training data\n",
    "df = pd.read_csv(data_file)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0         explanation why the edits made under my userna...\n1         daww he matches this background colour im seem...\n2         hey man im really not trying to edit war its j...\n3         more i cant make any real suggestions on impro...\n4         you sir are my hero any chance you remember wh...\n                                ...                        \n159566    and for the second time of asking when your vi...\n159567    you should be ashamed of yourself that is a ho...\n159568    spitzer umm theres no actual article for prost...\n159569    and it looks like it was actually you who put ...\n159570    and i really dont think you understand i came ...\nName: clean_comment, Length: 159571, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a basic text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase for uniformity\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the comment_text column\n",
    "df['clean_comment'] = df['comment_text'].apply(clean_text)\n",
    "df['clean_comment']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize the Sentence-BERT model (using a lightweight pre-trained model)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode the cleaned comments into dense vector representations\n",
    "embeddings = sbert_model.encode(df['clean_comment'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# This cell converts our preprocessed comments into numerical embeddings using Sentence-BERT, enabling the model to capture semantic meaning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the target label columns (adjust these based on your dataset)\n",
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Prepare feature and label arrays\n",
    "X = embeddings\n",
    "y = df[target_cols].values\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a multi-label classifier using OneVsRest strategy with logistic regression\n",
    "classifier = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set and display a classification report\n",
    "y_pred = classifier.predict(X_val)\n",
    "print(classification_report(y_val, y_pred, target_names=target_cols))\n",
    "\n",
    "# This cell trains a basic multi-label classifier on the Sentence-BERT embeddings and evaluates its performance."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
